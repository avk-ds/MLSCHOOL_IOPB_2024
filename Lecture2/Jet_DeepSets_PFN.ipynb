{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch#, torchvision, torchmetrics\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import tarfile\n",
    "import urllib\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uproot version :  5.0.11\n"
     ]
    }
   ],
   "source": [
    "print('Uproot version : ', uproot.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(torch.backends.cuda.is_built()) : \n",
    "    device='cuda'\n",
    "elif(torch.backends.mps.is_built()) : \n",
    "    device='mps'\n",
    "else : \n",
    "    device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/sanmay/Documents/ICTS_SCHOOL/Main_School/JetDataset/'\n",
    "example_file = dataset_path + 'JetClass_example_100k.root' # -- from -- \"https://hqu.web.cern.ch/datasets/JetClass/example/\" #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the content from the file\n",
    "tree = uproot.open(example_file)['tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.num_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part_px',\n",
       " 'part_py',\n",
       " 'part_pz',\n",
       " 'part_energy',\n",
       " 'part_deta',\n",
       " 'part_dphi',\n",
       " 'part_d0val',\n",
       " 'part_d0err',\n",
       " 'part_dzval',\n",
       " 'part_dzerr',\n",
       " 'part_charge',\n",
       " 'part_isChargedHadron',\n",
       " 'part_isNeutralHadron',\n",
       " 'part_isPhoton',\n",
       " 'part_isElectron',\n",
       " 'part_isMuon']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.keys(filter_name='part_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "part_px              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_py              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_pz              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_energy          | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_deta            | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_dphi            | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_d0val           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_d0err           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_dzval           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_dzerr           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_charge          | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_isChargedHadron | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "part_isNeutralHadron | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "part_isPhoton        | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "part_isElectron      | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "part_isMuon          | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "label_QCD            | float                    | AsDtype('>f4')\n",
      "label_Hbb            | bool                     | AsDtype('bool')\n",
      "label_Hcc            | bool                     | AsDtype('bool')\n",
      "label_Hgg            | bool                     | AsDtype('bool')\n",
      "label_H4q            | bool                     | AsDtype('bool')\n",
      "label_Hqql           | bool                     | AsDtype('bool')\n",
      "label_Zqq            | int32_t                  | AsDtype('>i4')\n",
      "label_Wqq            | int32_t                  | AsDtype('>i4')\n",
      "label_Tbqq           | int32_t                  | AsDtype('>i4')\n",
      "label_Tbl            | int32_t                  | AsDtype('>i4')\n",
      "jet_pt               | float                    | AsDtype('>f4')\n",
      "jet_eta              | float                    | AsDtype('>f4')\n",
      "jet_phi              | float                    | AsDtype('>f4')\n",
      "jet_energy           | float                    | AsDtype('>f4')\n",
      "jet_nparticles       | float                    | AsDtype('>f4')\n",
      "jet_sdmass           | float                    | AsDtype('>f4')\n",
      "jet_tau1             | float                    | AsDtype('>f4')\n",
      "jet_tau2             | float                    | AsDtype('>f4')\n",
      "jet_tau3             | float                    | AsDtype('>f4')\n",
      "jet_tau4             | float                    | AsDtype('>f4')\n",
      "aux_genpart_eta      | float                    | AsDtype('>f4')\n",
      "aux_genpart_phi      | float                    | AsDtype('>f4')\n",
      "aux_genpart_pid      | float                    | AsDtype('>f4')\n",
      "aux_genpart_pt       | float                    | AsDtype('>f4')\n",
      "aux_truth_match      | float                    | AsDtype('>f4')\n"
     ]
    }
   ],
   "source": [
    "# Display the content of the \"tree\"\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "label_QCD            | float                    | AsDtype('>f4')\n",
      "label_Hbb            | bool                     | AsDtype('bool')\n",
      "label_Hcc            | bool                     | AsDtype('bool')\n",
      "label_Hgg            | bool                     | AsDtype('bool')\n",
      "label_H4q            | bool                     | AsDtype('bool')\n",
      "label_Hqql           | bool                     | AsDtype('bool')\n",
      "label_Zqq            | int32_t                  | AsDtype('>i4')\n",
      "label_Wqq            | int32_t                  | AsDtype('>i4')\n",
      "label_Tbqq           | int32_t                  | AsDtype('>i4')\n",
      "label_Tbl            | int32_t                  | AsDtype('>i4')\n"
     ]
    }
   ],
   "source": [
    "tree.show(filter_name='label_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "jet_pt               | float                    | AsDtype('>f4')\n",
      "jet_eta              | float                    | AsDtype('>f4')\n",
      "jet_phi              | float                    | AsDtype('>f4')\n",
      "jet_energy           | float                    | AsDtype('>f4')\n",
      "jet_nparticles       | float                    | AsDtype('>f4')\n",
      "jet_sdmass           | float                    | AsDtype('>f4')\n",
      "jet_tau1             | float                    | AsDtype('>f4')\n",
      "jet_tau2             | float                    | AsDtype('>f4')\n",
      "jet_tau3             | float                    | AsDtype('>f4')\n",
      "jet_tau4             | float                    | AsDtype('>f4')\n"
     ]
    }
   ],
   "source": [
    "tree.show(filter_name='jet_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "part_px              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_py              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_pz              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_energy          | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_deta            | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_dphi            | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_d0val           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_d0err           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_dzval           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_dzerr           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_charge          | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "part_isChargedHadron | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "part_isNeutralHadron | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "part_isPhoton        | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "part_isElectron      | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "part_isMuon          | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n"
     ]
    }
   ],
   "source": [
    "tree.show(filter_name='part_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all arrays in the tree\n",
    "# Each array is a column of the table\n",
    "table = tree.arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arrays of a scalar type (bool/int/float) can be converted to a numpy array directly, e.g.\n",
    "table['label_Hcc'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40000, 40001, 40002, ..., 49997, 49998, 49999]),)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(table['label_H4q'].to_numpy()!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[38,\n",
       " 30,\n",
       " 39,\n",
       " 32,\n",
       " 45,\n",
       " 42,\n",
       " 41,\n",
       " 49,\n",
       " 49,\n",
       " 24,\n",
       " ...,\n",
       " 22,\n",
       " 29,\n",
       " 32,\n",
       " 52,\n",
       " 49,\n",
       " 30,\n",
       " 27,\n",
       " 31,\n",
       " 42]\n",
       "----------------------\n",
       "type: 100000 * float32</pre>"
      ],
      "text/plain": [
       "<Array [38, 30, 39, 32, 45, ..., 49, 30, 27, 31, 42] type='100000 * float32'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['jet_nparticles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = [ak.flatten(table[part_feat][1000:1001]).to_numpy() for part_feat in tree.keys(filter_name='part_*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42, 16), 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(feat_list).T.shape, len(tree.keys(filter_name='part_*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a Lorentz 4-vector from the (px, py, pz, energy) arrays\n",
    "p4 = vector.zip({'px': table['part_px'], 'py': table['part_py'], 'pz': table['part_pz'], 'energy': table['part_energy']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[[0.0442, 0, 0, 0.0221, -0.0221, ..., 0.000488, 0, 0, -0.000345, 0.000345],\n",
       " [0, 0.133, 0, 0.139, 0.14, ..., -0.000488, -0.000488, 0.000488, 0.494],\n",
       " [0, 0, 0.0156, 0, 0, 0.0156, ..., 0, 0.14, 0.14, -0.00138, 0.000977, 0.14],\n",
       " [0.177, 0.0884, 0.125, 0.133, 0.14, ..., 0, 0, 0, -0.000977, 0.000691],\n",
       " [0.125, 0.493, 0, 0, -0.011, ..., 0, 0.000488, -0.000488, -0.000488, 0.000488],\n",
       " [-0.0884, 0, 0.0442, 0.104, 0.492, ..., -0.000488, 0, 0.938, -0.000691, 0.14],\n",
       " [0, 0, 0.139, 0.139, 0.139, 0, ..., 0.14, 0.14, 0.000691, 0.494, 0, 0.000488],\n",
       " [-0.0221, 0.0312, -0.0312, 0.141, ..., -0.000488, 0.000488, -0.000345],\n",
       " [0, 0.14, 0, -0.011, 0.938, 0.494, 0.0156, ..., 0, 0.14, 0, 0.000488, 0, 0],\n",
       " [0.125, 0.0312, 0.14, 0.494, -0.0156, 0.139, ..., 0.14, 0, 0.00138, 0, 0],\n",
       " ...,\n",
       " [0.153, 0.133, 0, -0.011, 0.14, 0.14, ..., -0.000691, 0.14, 0, -0.000488, 0],\n",
       " [0, 0.0312, 0.495, 0.14, 0.141, ..., 0.000977, 0.14, 0, -0.000691, 0.000691],\n",
       " [0.125, 0.153, -0.0625, 0, 0, 0.14, ..., 0.00138, 0.00138, 0.14, 0.14, 0.14],\n",
       " [0.0221, 0.0156, 0.139, 0.011, 0.494, ..., -0.000691, 0.000488, 0, 0.000345],\n",
       " [0.14, -0.0312, 0.494, 0, -0.011, 0.494, 0.494, ..., 0, 0, 0, 0, -0.000488, 0],\n",
       " [0.0312, 0, 0.495, 0.139, 0.139, 0.011, ..., 0.14, 0, 0, -0.000488, -0.000244],\n",
       " [-0.0625, 0, 0, 0.139, 0.14, ..., 0.00138, -0.000977, 0.14, 0.14, 0.000691],\n",
       " [0.14, 0.14, 0.14, 0.14, 0.011, 0.00552, ..., -0.000977, 0, 0, 0.000488, 0],\n",
       " [-0.0625, 0.14, 0.0312, 0.139, 0.494, 0.494, ..., 0, 0, 0.14, 0, 0, 0.000345]]\n",
       "--------------------------------------------------------------------------------\n",
       "type: 100000 * var * float32</pre>"
      ],
      "text/plain": [
       "<Array [[0.0442, 0, ..., 0.000345], ..., [...]] type='100000 * var * float32'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4.mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.975435, 22.76201)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=12000\n",
    "ak.flatten(p4.pt[idx:idx+1]).to_numpy().mean(), ak.flatten(p4.pt[idx:idx+1]).to_numpy().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.5115892, 0.14769214)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.flatten(p4.phi[idx:idx+1]).to_numpy().mean(), ak.flatten(p4.phi[idx:idx+1]).to_numpy().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_sdmass = table['jet_sdmass'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_sdmass_H = jet_sdmass[np.where(table['label_Hbb'].to_numpy()!=0)]\n",
    "jet_sdmass_T = jet_sdmass[np.where(table['label_Tbqq'].to_numpy()!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 91.98812,  17.3149 , 124.49392, ..., 150.37427, 140.32726,\n",
       "       131.21666], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_sdmass_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(jet_sdmass_H, bins=np.linspace(0, 400, 50), label='Higgs', color='red', histtype='step', linewidth=2.)\n",
    "plt.hist(jet_sdmass_T, bins=np.linspace(0, 400, 50), label='Top', color='blue', histtype='step', linewidth=2.)\n",
    "plt.xlabel('Jet mass [GeV]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a jet dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jet_Dataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path:str, tree_name:str = 'tree') -> None:\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.dataset = uproot.open(dataset_path)\n",
    "        self.tree = self.dataset[tree_name].arrays()\n",
    "        \n",
    "        self.num_entries = self.dataset[tree_name].num_entries\n",
    "        \n",
    "        self.part_feat = self.dataset[tree_name].keys(filter_name='part_*')\n",
    "        self.jet_feat = self.dataset[tree_name].keys(filter_name='jet_*')\n",
    "        self.labels = self.dataset[tree_name].keys(filter_name='labels_*')\n",
    "        \n",
    "        \n",
    "        #self.pc_dataset = [ self.transform_jet_to_point_cloud(idx) for idx in range(self.num_entries-1) ]\n",
    "        \n",
    "\n",
    "    def transform_jet_to_point_cloud(self, idx:int) -> dict :\n",
    "    \n",
    "        npart = self.tree['jet_nparticles'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        part_feat_list = [ak.flatten(self.tree[part_feat][idx:idx+1]).to_numpy() for part_feat in self.part_feat]\n",
    "        \n",
    "        jet_pt = self.tree['jet_pt'].to_numpy()[idx:idx+1]\n",
    "        jet_eta = self.tree['jet_eta'].to_numpy()[idx:idx+1]\n",
    "        jet_phi = self.tree['jet_phi'].to_numpy()[idx:idx+1]\n",
    "        jet_energy = self.tree['jet_energy'].to_numpy()[idx:idx+1]\n",
    "        jet_tau21 = self.tree['jet_tau2'].to_numpy()[idx:idx+1]/self.tree['jet_tau1'].to_numpy()[idx:idx+1]\n",
    "        jet_tau32 = self.tree['jet_tau3'].to_numpy()[idx:idx+1]/self.tree['jet_tau2'].to_numpy()[idx:idx+1]\n",
    "        jet_tau43 = self.tree['jet_tau4'].to_numpy()[idx:idx+1]/self.tree['jet_tau3'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        \n",
    "        jet_sd_mass = self.tree['jet_sdmass'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        jet_feat = np.stack([jet_pt, jet_eta, jet_phi, jet_energy, jet_tau21, jet_tau32, jet_tau43]).T\n",
    "              \n",
    "        jet_feat = np.repeat(jet_feat, int(npart), axis=0)\n",
    "             \n",
    "        part_feat = np.stack(part_feat_list).T\n",
    "        \n",
    "        total_jet_feat = np.concatenate((part_feat, jet_feat), axis=-1)\n",
    "        total_jet_feat[np.isnan(total_jet_feat)] = 0.\n",
    "        \n",
    "        #print(type(total_jet_feat), 'total_jet_feat shape : ', total_jet_feat.shape)\n",
    "        \n",
    "        jet_class = -1\n",
    "        \n",
    "        if(self.tree['label_QCD'].to_numpy()[idx:idx+1] == 1) : jet_class = 0\n",
    "        \n",
    "        if( (self.tree['label_Tbqq'].to_numpy()[idx:idx+1] == 1) or\n",
    "            (self.tree['label_Tbl'].to_numpy()[idx:idx+1] == 1)) : jet_class = 3\n",
    "        \n",
    "        if( (self.tree['label_Zqq'].to_numpy()[idx:idx+1] == 1) or\n",
    "            (self.tree['label_Wqq'].to_numpy()[idx:idx+1] == 1)) : jet_class = 2\n",
    "        \n",
    "        if( (self.tree['label_Hbb'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hcc'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hgg'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_H4q'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hqql'].to_numpy()[idx:idx+1] == True) ) : jet_class = 1\n",
    "        \n",
    "        return {'jet' : torch.tensor(total_jet_feat), 'label' : torch.tensor([jet_class]), 'seq_length' : torch.tensor(npart),\n",
    "                'sd_mass' : torch.tensor(jet_sd_mass) \n",
    "                }     \n",
    "        \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.num_entries#len(self.pc_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx:int) -> dict :\n",
    "        # Return the idx-th data point of the dataset\n",
    "    \n",
    "        return self.transform_jet_to_point_cloud(idx)#self.pc_dataset[idx]#data_point, data_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_dataset = Jet_Dataset(dataset_path=example_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jet_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_dataset[16883]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(data_list : list) -> tuple : \n",
    "    \n",
    "    max_length = np.max([ int( data_list[idx]['seq_length'].item() ) for idx in range(len(data_list))  ])\n",
    "    # print(max_length)\n",
    "    pc_list, label_list = [], [] \n",
    "    \n",
    "    for idx in range(len(data_list)) : \n",
    "        \n",
    "        \n",
    "        pc, label = data_list[idx]['jet'], data_list[idx]['label']\n",
    "        \n",
    "        N, C = pc.shape[0], pc.shape[1]\n",
    "        \n",
    "        pc_padded = torch.zeros([1, max_length, C])\n",
    "        \n",
    "        pc = pc.reshape(1, N, C) # (N, C) -> (1, N, C)\n",
    "        \n",
    "        pc_padded[:, 0 : N, :   ] = pc[:,:,:] # \n",
    "        \n",
    "        pc_list.append(pc_padded)\n",
    "        label_list.append( torch.tensor([label]) )\n",
    "    \n",
    "\n",
    "    return torch.cat(pc_list, dim=0), torch.cat(label_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_dataloader = data.DataLoader(dataset=jet_dataset, batch_size=5, shuffle=True, collate_fn=create_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_data, labels = next(iter(jet_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 40, 23])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.deepsets import DeepSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSet(in_features=23, feats=[25, 20, 15, 10, 6], n_class=4)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(jet_data.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([5]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the training block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    \n",
    "    train_loss_ep = 0.\n",
    "    \n",
    "    model.train()\n",
    "    #for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    with tqdm.tqdm(train_loader, ascii=True) as tq:\n",
    "        for data, target in tq:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_ep += loss.item() * data.size(0)\n",
    "        \n",
    "    return train_loss_ep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the testing block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    \n",
    "    test_loss_ep = 0.\n",
    "    \n",
    "    model.eval()\n",
    "    #for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    with tqdm.tqdm(train_loader, ascii=True) as tq:\n",
    "        for data, target in tq:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            \n",
    "            test_loss_ep += loss.item() * data.size(0)\n",
    "        \n",
    "    return test_loss_ep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's prepare the full dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 20000\n"
     ]
    }
   ],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 5\n",
    "# percentage of training set to use as validation\n",
    "train_size, valid_size = 0.6, 0.2\n",
    "# # convert data to torch.FloatTensor\n",
    "# transform = transforms.ToTensor()\n",
    "# choose the training and testing datasets\n",
    "# obtain training indices that will be used for validation\n",
    "jet_dataset = Jet_Dataset(dataset_path=example_file)\n",
    "num_train = len(jet_dataset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "train_split = int(np.floor(train_size * num_train))\n",
    "valid_split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "print(train_split, valid_split)\n",
    "train_index, valid_index, test_index = indices[0:train_split], indices[train_split:train_split + valid_split], indices[train_split + valid_split:]\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_index)\n",
    "valid_sampler = SubsetRandomSampler(valid_index)\n",
    "test_sampler = SubsetRandomSampler(test_index)\n",
    "# prepare data loaders\n",
    "train_loader = data.DataLoader(dataset=jet_dataset, batch_size = batch_size, \n",
    "                                           num_workers = num_workers, sampler = train_sampler, collate_fn=create_batch)\n",
    "valid_loader = data.DataLoader(dataset=jet_dataset, batch_size = batch_size,\n",
    "                                          num_workers = num_workers,  sampler = valid_sampler, collate_fn=create_batch)\n",
    "test_loader = data.DataLoader(dataset=jet_dataset, batch_size = batch_size,\n",
    "                                          num_workers = num_workers,  sampler = test_sampler, collate_fn=create_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Define the optimizer --- #\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|#1        | 1366/12000 [00:56<06:33, 27.03it/s]/var/folders/27/j7vqc09s6999lx6q2v5txbrm0000gn/T/ipykernel_41598/1360868746.py:37: RuntimeWarning: invalid value encountered in divide\n",
      "  jet_tau43 = self.tree['jet_tau4'].to_numpy()[idx:idx+1]/self.tree['jet_tau3'].to_numpy()[idx:idx+1]\n",
      "100%|##########| 12000/12000 [07:51<00:00, 25.46it/s]\n",
      "100%|##########| 12000/12000 [06:54<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.190942 \tValidation Loss: 3.537704\n",
      "Validation loss decreased (inf --> 3.537704).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [18:26<00:00, 10.85it/s]  \n",
      "100%|##########| 12000/12000 [06:45<00:00, 29.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 1.173705 \tValidation Loss: 3.514536\n",
      "Validation loss decreased (3.537704 --> 3.514536).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:29<00:00, 26.69it/s]\n",
      "100%|##########| 12000/12000 [06:37<00:00, 30.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 1.164619 \tValidation Loss: 3.490329\n",
      "Validation loss decreased (3.514536 --> 3.490329).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:50<00:00, 25.49it/s]\n",
      "100%|##########| 12000/12000 [07:03<00:00, 28.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 1.161300 \tValidation Loss: 3.464391\n",
      "Validation loss decreased (3.490329 --> 3.464391).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:54<00:00, 25.32it/s]\n",
      "100%|##########| 12000/12000 [06:48<00:00, 29.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 1.159934 \tValidation Loss: 3.497932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [08:08<00:00, 24.58it/s]\n",
      "100%|##########| 12000/12000 [06:47<00:00, 29.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 1.159226 \tValidation Loss: 3.465642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:47<00:00, 25.69it/s]\n",
      "100%|##########| 12000/12000 [06:36<00:00, 30.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 1.156917 \tValidation Loss: 3.496719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:43<00:00, 25.86it/s]\n",
      "100%|##########| 12000/12000 [06:50<00:00, 29.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 1.157089 \tValidation Loss: 3.474123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:52<00:00, 25.37it/s]\n",
      "100%|##########| 12000/12000 [06:36<00:00, 30.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.156283 \tValidation Loss: 3.460565\n",
      "Validation loss decreased (3.464391 --> 3.460565).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:56<00:00, 25.21it/s]\n",
      "100%|##########| 12000/12000 [06:40<00:00, 29.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 1.154202 \tValidation Loss: 3.463111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:48<00:00, 25.61it/s]\n",
      "100%|##########| 12000/12000 [06:37<00:00, 30.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 1.153623 \tValidation Loss: 3.453419\n",
      "Validation loss decreased (3.460565 --> 3.453419).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:39<00:00, 26.12it/s]\n",
      "100%|##########| 12000/12000 [06:50<00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 1.153132 \tValidation Loss: 3.439516\n",
      "Validation loss decreased (3.453419 --> 3.439516).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:57<00:00, 25.12it/s]\n",
      "100%|##########| 12000/12000 [06:50<00:00, 29.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 1.152468 \tValidation Loss: 3.466441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:48<00:00, 25.59it/s]\n",
      "100%|##########| 12000/12000 [06:57<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 1.152323 \tValidation Loss: 3.456443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:54<00:00, 25.28it/s]\n",
      "100%|##########| 12000/12000 [06:49<00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 1.150017 \tValidation Loss: 3.468603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [08:00<00:00, 24.99it/s]\n",
      "100%|##########| 12000/12000 [06:43<00:00, 29.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 1.150506 \tValidation Loss: 3.457710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [08:06<00:00, 24.69it/s]\n",
      "100%|##########| 12000/12000 [07:15<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tTraining Loss: 1.148725 \tValidation Loss: 3.444675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [11:20<00:00, 17.64it/s]\n",
      "100%|##########| 12000/12000 [55:15<00:00,  3.62it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tTraining Loss: 1.148848 \tValidation Loss: 3.427359\n",
      "Validation loss decreased (3.439516 --> 3.427359).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [11:02<00:00, 18.11it/s]  \n",
      "100%|##########| 12000/12000 [08:01<00:00, 24.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 1.155505 \tValidation Loss: 3.488835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 12000/12000 [07:50<00:00, 25.49it/s]\n",
      "100%|##########| 12000/12000 [06:49<00:00, 29.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tTraining Loss: 1.150035 \tValidation Loss: 3.431298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf  # set initial \"min\" to infinity\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor losses\n",
    "    \n",
    "    train_loss = train(model, device, train_loader, optimizer)\n",
    "    \n",
    "    valid_loss = test(model, device, valid_loader)\n",
    "    \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss / len(train_loader.sampler)\n",
    "    valid_loss = valid_loss / len(valid_loader.sampler)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        valid_loss\n",
    "        ))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_jet.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSet(\n",
       "  (sequential): ModuleList(\n",
       "    (0): DeepSetLayer(\n",
       "      (Gamma): Linear(in_features=23, out_features=25, bias=True)\n",
       "      (Lambda): Linear(in_features=23, out_features=25, bias=True)\n",
       "    )\n",
       "    (1): ReLU()\n",
       "    (2): DeepSetLayer(\n",
       "      (Gamma): Linear(in_features=25, out_features=20, bias=True)\n",
       "      (Lambda): Linear(in_features=25, out_features=20, bias=True)\n",
       "    )\n",
       "    (3): ReLU()\n",
       "    (4): DeepSetLayer(\n",
       "      (Gamma): Linear(in_features=20, out_features=15, bias=True)\n",
       "      (Lambda): Linear(in_features=20, out_features=15, bias=True)\n",
       "    )\n",
       "    (5): ReLU()\n",
       "    (6): DeepSetLayer(\n",
       "      (Gamma): Linear(in_features=15, out_features=10, bias=True)\n",
       "      (Lambda): Linear(in_features=15, out_features=10, bias=True)\n",
       "    )\n",
       "    (7): ReLU()\n",
       "    (8): DeepSetLayer(\n",
       "      (Gamma): Linear(in_features=10, out_features=6, bias=True)\n",
       "      (Lambda): Linear(in_features=10, out_features=6, bias=True)\n",
       "    )\n",
       "    (9): DeepSetLayer(\n",
       "      (Gamma): Linear(in_features=6, out_features=4, bias=True)\n",
       "      (Lambda): Linear(in_features=6, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test = DeepSet(in_features=23, feats=[25, 20, 15, 10, 6], n_class=4)\n",
    "model_test.load_state_dict(torch.load('model_jet.pt'))\n",
    "model_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader):\n",
    "    model.eval() # Set model to eval mode\n",
    "    true_preds, num_preds = 0., 0.\n",
    "    \n",
    "    with torch.no_grad(): # Deactivate gradients for the following code\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            \n",
    "            # Determine prediction of model on dev set\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            # preds = preds.squeeze(dim=1)\n",
    "            # preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
    "            pred_labels = torch.argmax(preds, dim=-1) # Binarize predictions to 0 and 10\n",
    "            \n",
    "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
    "            true_preds += (pred_labels == data_labels).sum()\n",
    "            num_preds += data_labels.shape[0]\n",
    "            \n",
    "    acc = true_preds / num_preds\n",
    "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 50.66%\n"
     ]
    }
   ],
   "source": [
    "eval_model(model_test, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What will you do to regress jet mass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
