{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.3.1\n",
      "PyG version 2.5.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential\n",
    "from torch import Tensor\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptPairTensor,\n",
    "    OptTensor,\n",
    "    Size,\n",
    "    SparseTensor,\n",
    "    torch_sparse,\n",
    ")\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse, to_undirected\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, knn_graph\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_scatter import scatter\n",
    "from torch_cluster import knn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "import awkward as ak\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a dataset where we put Jet properties as global data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jet_Dataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path:str, tree_name:str = 'tree', k:int = 5) -> None:\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super(Jet_Dataset, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.dataset = uproot.open(dataset_path)\n",
    "        self.tree = self.dataset[tree_name].arrays()\n",
    "        \n",
    "        self.num_entries = self.dataset[tree_name].num_entries\n",
    "        \n",
    "        self.part_feat = self.dataset[tree_name].keys(filter_name='part_*')\n",
    "        self.jet_feat = self.dataset[tree_name].keys(filter_name='jet_*')\n",
    "        self.labels = self.dataset[tree_name].keys(filter_name='labels_*')\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "        \n",
    "        #self.pc_dataset = [ self.transform_jet_to_point_cloud(idx) for idx in range(self.num_entries-1) ]\n",
    "        \n",
    "\n",
    "    def transform_jet_to_point_cloud(self, idx:int) -> Data :\n",
    "    \n",
    "        npart = self.tree['jet_nparticles'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        part_feat_list = [ak.flatten(self.tree[part_feat][idx:idx+1]).to_numpy() for part_feat in self.part_feat]\n",
    "        \n",
    "        jet_pt = self.tree['jet_pt'].to_numpy()[idx:idx+1]\n",
    "        jet_eta = self.tree['jet_eta'].to_numpy()[idx:idx+1]\n",
    "        jet_phi = self.tree['jet_phi'].to_numpy()[idx:idx+1]\n",
    "        jet_energy = self.tree['jet_energy'].to_numpy()[idx:idx+1]\n",
    "        jet_tau21 = self.tree['jet_tau2'].to_numpy()[idx:idx+1]/self.tree['jet_tau1'].to_numpy()[idx:idx+1]\n",
    "        jet_tau32 = self.tree['jet_tau3'].to_numpy()[idx:idx+1]/self.tree['jet_tau2'].to_numpy()[idx:idx+1]\n",
    "        jet_tau43 = self.tree['jet_tau4'].to_numpy()[idx:idx+1]/self.tree['jet_tau3'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        \n",
    "        jet_sd_mass = self.tree['jet_sdmass'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        jet_feat = np.stack([jet_pt, jet_eta, jet_phi, jet_energy, jet_tau21, jet_tau32, jet_tau43]).T\n",
    "              \n",
    "        #jet_feat = np.repeat(jet_feat, int(npart), axis=0)\n",
    "             \n",
    "        part_feat = np.stack(part_feat_list).T\n",
    "        \n",
    "        total_jet_feat = part_feat #np.concatenate((part_feat, jet_feat), axis=-1)\n",
    "        total_jet_feat[np.isnan(total_jet_feat)] = 0.\n",
    "        \n",
    "        #print(type(total_jet_feat), 'total_jet_feat shape : ', total_jet_feat.shape)\n",
    "        \n",
    "        jet_class = -1\n",
    "        \n",
    "        if(self.tree['label_QCD'].to_numpy()[idx:idx+1] == 1) : jet_class = 0\n",
    "        \n",
    "        if( (self.tree['label_Tbqq'].to_numpy()[idx:idx+1] == 1) or\n",
    "            (self.tree['label_Tbl'].to_numpy()[idx:idx+1] == 1)) : jet_class = 2\n",
    "        \n",
    "        if( (self.tree['label_Zqq'].to_numpy()[idx:idx+1] == 1) or\n",
    "            (self.tree['label_Wqq'].to_numpy()[idx:idx+1] == 1)) : jet_class = 0\n",
    "        \n",
    "        if( (self.tree['label_Hbb'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hcc'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hgg'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_H4q'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hqql'].to_numpy()[idx:idx+1] == True) ) : jet_class = 1\n",
    "        \n",
    "        part_eta = torch.tensor( ak.flatten(self.tree['part_deta'][idx:idx+1]).to_numpy() )\n",
    "        part_phi = torch.tensor( ak.flatten(self.tree['part_dphi'][idx:idx+1]).to_numpy() )\n",
    "        eta_phi_pos = torch.stack([part_eta, part_phi], dim=-1)\n",
    "        \n",
    "        edge_index = torch_geometric.nn.pool.knn_graph(x = eta_phi_pos, k = self.k)\n",
    "        \n",
    "        src, dst = edge_index\n",
    "                \n",
    "        part_del_eta = part_eta[dst] - part_eta[src]\n",
    "        part_del_phi = part_phi[dst] - part_phi[src]\n",
    "        \n",
    "        part_del_R = torch.hypot(part_del_eta, part_del_phi).view(-1, 1) # -- why do we need this view function ? \n",
    "        \n",
    "        data = Data(x=torch.tensor(total_jet_feat), edge_index=edge_index, edge_deltaR = part_del_R)\n",
    "        data.label = torch.tensor([jet_class])\n",
    "        data.sd_mass = torch.tensor(jet_sd_mass)\n",
    "        data.global_data = torch.tensor(jet_feat)\n",
    "        data.seq_length = torch.tensor(npart)\n",
    "        \n",
    "        return data    \n",
    "        \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.num_entries#len(self.pc_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx:int) -> Data :\n",
    "        # Return the idx-th data point of the dataset\n",
    "    \n",
    "        return self.transform_jet_to_point_cloud(idx)#self.pc_dataset[idx]#data_point, data_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For later convenience we build a function to make MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(inputsize,outputsize,features,add_batch_norm=False,add_activation=None):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(inputsize,features[0]))\n",
    "    layers.append(nn.ReLU())\n",
    "    for hidden_i in range(1,len(features)):\n",
    "        if add_batch_norm:\n",
    "            layers.append(nn.BatchNorm1d(features[hidden_i-1]))\n",
    "        layers.append(nn.Linear(features[hidden_i-1],features[hidden_i]))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.Linear(features[-1],outputsize))\n",
    "    if add_activation!=None:\n",
    "        layers.append(add_activation)\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=6, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=6, out_features=3, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_mlp(inputsize=3, outputsize=4, features=[5, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/sanmay/Documents/ICTS_SCHOOL/Main_School/JetDataset/'\n",
    "file_name = dataset_path + 'JetClass_example_100k.root' # -- from -- \"https://hqu.web.cern.ch/datasets/JetClass/example/\" #\n",
    "jet_dataset = Jet_Dataset(dataset_path=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=jet_dataset, batch_size=5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_b = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[196, 16], edge_index=[2, 980], edge_deltaR=[980, 1], label=[5], sd_mass=[5], global_data=[5, 7], seq_length=[5], batch=[196], ptr=[6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is graph network?\n",
    "\n",
    "Here, we recapitulate the \"graph network\" (GN) formalism {cite:p}`battaglia2018relational`, which generalizes various GNNs and other similar methods.\n",
    "GNs are graph-to-graph mappings, whose output graphs have the same node and edge structure as the input. \n",
    "Formally, a GN block contains three \"update\" functions, $\\phi$, and three \"aggregation\" functions, $\\rho$.\n",
    "The stages of processing in a single GN block are:\n",
    "\n",
    "<img src=\"GN-full-block.png\" alt=\"Alternative text\" />\n",
    "\n",
    "where $E'_i = \\left\\{\\left(\\mathbf{e}'_k, r_k, s_k \\right)\\right\\}_{r_k=i,\\; k=1:N^e}$ contains the updated edge features for edges whose receiver node is the $i$th node, $E' = \\bigcup_i E_i' = \\left\\{\\left(\\mathbf{e}'_k, r_k, s_k \\right)\\right\\}_{k=1:N^e}$ is the set of updated edges, and $V'=\\left\\{\\mathbf{v}'_i\\right\\}_{i=1:N^v}$ is the set of updated nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a MetaLayer\n",
    "\n",
    "from https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/models/meta.html#MetaLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLayer(torch.nn.Module):\n",
    "    r\"\"\"A meta layer for building any kind of graph network, inspired by the\n",
    "    `\"Relational Inductive Biases, Deep Learning, and Graph Networks\"\n",
    "    <https://arxiv.org/abs/1806.01261>`_ paper.\n",
    "\n",
    "    A graph network takes a graph as input and returns an updated graph as\n",
    "    output (with same connectivity).\n",
    "    The input graph has node features :obj:`x`, edge features :obj:`edge_attr`\n",
    "    as well as graph-level features :obj:`u`.\n",
    "    The output graph has the same structure, but updated features.\n",
    "\n",
    "    Edge features, node features as well as global features are updated by\n",
    "    calling the modules :obj:`edge_model`, :obj:`node_model` and\n",
    "    :obj:`global_model`, respectively.\n",
    "\n",
    "    To allow for batch-wise graph processing, all callable functions take an\n",
    "    additional argument :obj:`batch`, which determines the assignment of\n",
    "    edges or nodes to their specific graphs.\n",
    "\n",
    "    Args:\n",
    "        edge_model (torch.nn.Module, optional): A callable which updates a\n",
    "            graph's edge features based on its source and target node features,\n",
    "            its current edge features and its global features.\n",
    "            (default: :obj:`None`)\n",
    "        node_model (torch.nn.Module, optional): A callable which updates a\n",
    "            graph's node features based on its current node features, its graph\n",
    "            connectivity, its edge features and its global features.\n",
    "            (default: :obj:`None`)\n",
    "        global_model (torch.nn.Module, optional): A callable which updates a\n",
    "            graph's global features based on its node features, its graph\n",
    "            connectivity, its edge features and its current global features.\n",
    "            (default: :obj:`None`)\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "        from torch_geometric.utils import scatter\n",
    "        from torch_geometric.nn import MetaLayer\n",
    "\n",
    "        class EdgeModel(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.edge_mlp = Seq(Lin(..., ...), ReLU(), Lin(..., ...))\n",
    "\n",
    "            def forward(self, src, dst, edge_attr, u, batch):\n",
    "                # src, dst: [E, F_x], where E is the number of edges.\n",
    "                # edge_attr: [E, F_e]\n",
    "                # u: [B, F_u], where B is the number of graphs.\n",
    "                # batch: [E] with max entry B - 1.\n",
    "                out = torch.cat([src, dst, edge_attr, u[batch]], 1)\n",
    "                return self.edge_mlp(out)\n",
    "\n",
    "        class NodeModel(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.node_mlp_1 = Seq(Lin(..., ...), ReLU(), Lin(..., ...))\n",
    "                self.node_mlp_2 = Seq(Lin(..., ...), ReLU(), Lin(..., ...))\n",
    "\n",
    "            def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "                # x: [N, F_x], where N is the number of nodes.\n",
    "                # edge_index: [2, E] with max entry N - 1.\n",
    "                # edge_attr: [E, F_e]\n",
    "                # u: [B, F_u]\n",
    "                # batch: [N] with max entry B - 1.\n",
    "                row, col = edge_index\n",
    "                out = torch.cat([x[row], edge_attr], dim=1)\n",
    "                out = self.node_mlp_1(out)\n",
    "                out = scatter(out, col, dim=0, dim_size=x.size(0),\n",
    "                              reduce='mean')\n",
    "                out = torch.cat([x, out, u[batch]], dim=1)\n",
    "                return self.node_mlp_2(out)\n",
    "\n",
    "        class GlobalModel(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.global_mlp = Seq(Lin(..., ...), ReLU(), Lin(..., ...))\n",
    "\n",
    "            def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "                # x: [N, F_x], where N is the number of nodes.\n",
    "                # edge_index: [2, E] with max entry N - 1.\n",
    "                # edge_attr: [E, F_e]\n",
    "                # u: [B, F_u]\n",
    "                # batch: [N] with max entry B - 1.\n",
    "                out = torch.cat([\n",
    "                    u,\n",
    "                    scatter(x, batch, dim=0, reduce='mean'),\n",
    "                ], dim=1)\n",
    "                return self.global_mlp(out)\n",
    "\n",
    "        op = MetaLayer(EdgeModel(), NodeModel(), GlobalModel())\n",
    "        x, edge_attr, u = op(x, edge_index, edge_attr, u, batch)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        edge_model: Optional[torch.nn.Module] = None,\n",
    "        node_model: Optional[torch.nn.Module] = None,\n",
    "        global_model: Optional[torch.nn.Module] = None,\n",
    "       ):\n",
    "        super(MetaLayer, self).__init__()\n",
    "        self.edge_model = edge_model\n",
    "        self.node_model = node_model\n",
    "        self.global_model = global_model\n",
    "\n",
    "        #self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        for item in [self.node_model, self.edge_model, self.global_model]:\n",
    "            if hasattr(item, 'reset_parameters'):\n",
    "                item.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        edge_attr: Optional[Tensor] = None,\n",
    "        u: Optional[Tensor] = None,\n",
    "        batch: Optional[Tensor] = None,\n",
    "        ) -> Tuple[Tensor, Optional[Tensor], Optional[Tensor]]:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): The node features.\n",
    "            edge_index (torch.Tensor): The edge indices.\n",
    "            edge_attr (torch.Tensor, optional): The edge features.\n",
    "                (default: :obj:`None`)\n",
    "            u (torch.Tensor, optional): The global graph features.\n",
    "                (default: :obj:`None`)\n",
    "            batch (torch.Tensor, optional): The batch vector\n",
    "                :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns\n",
    "                each node to a specific graph. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        row = edge_index[0]\n",
    "        col = edge_index[1]\n",
    "\n",
    "        if self.edge_model is not None:\n",
    "            edge_attr = self.edge_model(x[row], x[col], edge_attr, u,\n",
    "                                        batch if batch is None else batch[row])\n",
    "\n",
    "        if self.node_model is not None:\n",
    "            x = self.node_model(x, edge_index, edge_attr, u, batch)\n",
    "\n",
    "        if self.global_model is not None:\n",
    "            u = self.global_model(x, edge_index, edge_attr, u, batch)\n",
    "\n",
    "        return x, edge_attr, u\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(\\n'\n",
    "                f'  edge_model={self.edge_model},\\n'\n",
    "                f'  node_model={self.node_model},\\n'\n",
    "                f'  global_model={self.global_model}\\n'\n",
    "                f')')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's declare the edge_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeModel(nn.Module):\n",
    "    def __init__(self, input_edge_dim:int, output_edge_dim:int, node_dim:int, global_dim:int, features:list ):\n",
    "        super(EdgeModel, self).__init__()\n",
    "        self.edge_mlp = build_mlp(inputsize=2*node_dim+global_dim+input_edge_dim, outputsize=output_edge_dim, features=features)\n",
    "\n",
    "    def forward(self, src, dst, edge_attr, u, edge_batch):\n",
    "        # src, dst: [E, F_x], where E is the number of edges.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u], where B is the number of graphs.\n",
    "        # batch: [E] with max entry B - 1.\n",
    "        out = torch.cat([src, dst, edge_attr, u[edge_batch]], dim=1)\n",
    "        return self.edge_mlp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 196)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_b.num_edges, gr_b.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_idx, dst_idx = gr_b.edge_index\n",
    "src, dst = gr_b.x[src_idx], gr_b.x[dst_idx]\n",
    "edge_attr = gr_b.edge_deltaR\n",
    "u = gr_b.global_data\n",
    "batch = gr_b.batch\n",
    "node_batch = gr_b.batch\n",
    "edge_batch = gr_b.batch[src_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, node_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src shape :  torch.Size([980, 16])  dst shape :  torch.Size([980, 16])\n",
      "edge attribute shape :  torch.Size([980, 1])\n",
      "global attribute shape :  torch.Size([5, 7])\n",
      "batch :  torch.Size([980])\n",
      "global data edge replicated shape :  torch.Size([980, 7])\n"
     ]
    }
   ],
   "source": [
    "print('src shape : ', src.shape, ' dst shape : ', dst.shape)\n",
    "print('edge attribute shape : ', edge_attr.shape)\n",
    "print('global attribute shape : ', u.shape)\n",
    "print('batch : ', edge_batch.shape)\n",
    "print('global data edge replicated shape : ', u[edge_batch].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_network = EdgeModel(input_edge_dim=1, output_edge_dim=3, node_dim=16, global_dim=7, features=[3,4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated_edge shape :  torch.Size([980, 3])\n"
     ]
    }
   ],
   "source": [
    "updated_edge = edge_network(src=src, dst=dst, edge_attr=edge_attr, u=u, edge_batch=edge_batch)\n",
    "print('updated_edge shape : ', updated_edge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's build a node_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeModel(torch.nn.Module):\n",
    "    def __init__(self, input_edge_dim:int, input_node_dim:int, output_node_dim:int, global_dim:int, features:list):\n",
    "        super(NodeModel, self).__init__()\n",
    "        self.node_mlp = build_mlp(inputsize=input_edge_dim+input_node_dim+global_dim, outputsize=output_node_dim, features=features)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "        row, col = edge_index\n",
    "        \n",
    "        out = scatter(edge_attr, col, dim=0, dim_size=x.size(0),\n",
    "                        reduce='mean')\n",
    "        print('Agrregated out shape : ', out.shape)\n",
    "        \n",
    "        out = torch.cat([x, out, u[batch]], dim=1)\n",
    "        print('Stacked out shape : ', out.shape)\n",
    "        return self.node_mlp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_edge.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_network = NodeModel(input_edge_dim = updated_edge.shape[-1], input_node_dim=gr_b.x.shape[-1], output_node_dim=4, global_dim=u.shape[-1], features=[3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrregated out shape :  torch.Size([196, 3])\n",
      "Stacked out shape :  torch.Size([196, 26])\n"
     ]
    }
   ],
   "source": [
    "updated_node = node_network(gr_b.x, edge_index=gr_b.edge_index,edge_attr=updated_edge, u=u, batch=node_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally the global update network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalModel(torch.nn.Module):\n",
    "    def __init__(self, input_edge_dim:int, input_node_dim:int, input_global_dim:int, output_global_dim:int, features:list):\n",
    "        super(GlobalModel, self).__init__()\n",
    "        self.global_mlp = build_mlp(inputsize=input_edge_dim+input_node_dim+input_global_dim, outputsize=output_global_dim, features=features)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "        src_idx, dst_idx = edge_index\n",
    "        \n",
    "        out = torch.cat([\n",
    "            u,\n",
    "            scatter(x, batch, dim=0, reduce='mean'),\n",
    "            scatter(edge_attr, batch[src_idx], dim=0, reduce='mean')\n",
    "        ], dim=1)\n",
    "        return self.global_mlp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_network = GlobalModel(input_edge_dim=3, input_node_dim=4, input_global_dim=7, output_global_dim=5, features=[3,4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_global_data = global_network(x=updated_node, edge_index=gr_b.edge_index,edge_attr=updated_edge, u=u, batch=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_global_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The full GNN model at one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_layer = MetaLayer(edge_model=edge_network,\n",
    "                      node_model=node_network,\n",
    "                      global_model=global_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment : By construction, edge_model, node_model and gobal_model can be instances of MessagePassing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrregated out shape :  torch.Size([196, 3])\n",
      "Stacked out shape :  torch.Size([196, 26])\n"
     ]
    }
   ],
   "source": [
    "x1, edge_attr1, u1 = gnn_layer(x=gr_b.x, edge_index=gr_b.edge_index,edge_attr=gr_b.edge_deltaR, u=u, batch=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW : Make a GNN model by stacking two Meta-Layers and setup a model which will identify if the nodes are hadrons or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
